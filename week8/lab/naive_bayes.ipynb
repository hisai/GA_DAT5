{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "Concepts in this Notebook:\n",
    "- Naive Bayes Classifiers\n",
    "- Train Test Split\n",
    "- Vectorizer (fit and transform)\n",
    "- Accuracy of training and test data\n",
    "- Sparse array vs normal array\n",
    "- Comparing classifiers in sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some extra resources:\n",
    "\n",
    "- [SKL Naive Bayes Documentation](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "- [Stanford Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = pd.read_csv('https://raw.githubusercontent.com/gfleetwood/fall-2014-lessons/master/datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A winning animated feature that has something for everyone on the age spectrum.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.quote[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication                                              quote review_date    rtid      title\n",
       "0         Derek Adams  fresh  114709.0        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559.0  Toy story\n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559.0  Toy story\n",
       "2         David Ansen  fresh  114709.0        Newsweek  A winning animated feature that has something ...  2008-08-18  9559.0  Toy story\n",
       "3       Leonard Klady  fresh  114709.0         Variety  The film sports a provocative and appealing st...  2008-06-09  9559.0  Toy story\n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0  Toy story"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial vs Bernoulli Models\n",
    "\n",
    "- The **Multinomial model** actually counts occurences out of all possible occurences for probability - better for greater features\n",
    "- The **Bernoulli model** counts only all documents with presence of the word - better for fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - import both versions of naive bayes from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Count Vectorizer Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-f274000ccf41>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-f274000ccf41>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    print \"Original text:\\n\\t\", '\\n\\t'.join(text)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "### How the Count Vectorizer Works\n",
    "#\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
    "print \"Original text:\\n\\t\", '\\n\\t'.join(text)\n",
    "\n",
    "# TODO - create the instance of CountVectorizer class. Specify the ngram_range argument (see docs)\n",
    "\n",
    "# TODO - call `fit` on the text to build the vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is an ngram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the names of the features (n grams)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO call `transform` to convert text to a bag of words\n",
    "# x = ...\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
    "# convert back to a \"normal\" numpy array\n",
    "x_back = x.toarray()\n",
    "x_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Transformed text vector is \\n\", x\n",
    "\n",
    "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
    "print\n",
    "print \"Words for each feature:\"\n",
    "print vectorizer.get_feature_names()\n",
    "\n",
    "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
    "# just their frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Features (X) and Target (Y) for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a (nreview, nwords) array. Each row corresponds to a bag-of-words representation for a single review. This will be the input to the model.\n",
    "\n",
    "Y is a nreview-element 1/0 array, encoding whether a review is Fresh (1) or Rotten (0). This is the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer with n-grams of length one or two\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Create a vector where each row is bag-of-words for a single quote\n",
    "X = vectorizer.fit_transform(critics.quote) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Create an array where each element encodes whether the array is Fresh or Rotten\n",
    "# Y = ...\n",
    "# hint: apply the == condition, then use .values.astype(np.int) on the result to get the right type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SKLearn's train_test_split\n",
    "# Important - we'll do this a thousand times\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of all quotes\n",
    "rotten_vectorizer = vectorizer.fit(critics.quote)\n",
    "\n",
    "# a few helper functions\n",
    "def accuracy_report(_clf):\n",
    "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
    "\n",
    "    #Print the accuracy on the test and training dataset\n",
    "    training_accuracy = _clf.score(xtrain, ytrain)\n",
    "    test_accuracy = _clf.score(xtest, ytest)\n",
    "\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    \n",
    "# a function to run some tests\n",
    "def AnalyzeReview(testquote, _clf):\n",
    "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
    "    testquote = rotten_vectorizer.transform([testquote])\n",
    "\n",
    "    if (_clf.predict(testquote)[0] == 1):\n",
    "        print \"... a fresh review.\"\n",
    "    else:\n",
    "        print \"... a rotten review.\"\n",
    "    return(clf.predict(testquote)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print \"MultinomialNB:\"\n",
    "clf_mn = MultinomialNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print \"BernoulliNB:\"\n",
    "# TODO - same as above with Bernoulli\n",
    "# clf_b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print \"Logistic Regression:\"\n",
    "# TODO - same as above with LogReg\n",
    "# clf_lr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnalyzeReview(\"This movie was awesome\", clf_mn)\n",
    "AnalyzeReview(\"This movie was awesome\", clf_b)\n",
    "AnalyzeReview(\"This movie was awesome\", clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction and probability\n",
    "\n",
    "# Outputs of X (just first column)\n",
    "prob = clf.predict_proba(X)[:, 0]\n",
    "\n",
    "predict = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y==0 #(provides a mask where the actual review is bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argsort returns the positions of the top n sorted values\n",
    "np.argsort((prob[Y==0]))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Review classification errors\n",
    "bad_rotten = np.argsort(prob[Y == 0])[:5]\n",
    "bad_fresh = np.argsort(prob[Y == 1])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Mis-predicted Rotten quotes\"\n",
    "print '---------------------------'\n",
    "for row in bad_rotten:\n",
    "    print critics[Y == 0].quote.irow(row)\n",
    "    print\n",
    "\n",
    "print \"Mis-predicted Fresh quotes\"\n",
    "print '--------------------------'\n",
    "for row in bad_fresh:\n",
    "    print critics[Y == 1].quote.irow(row)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
